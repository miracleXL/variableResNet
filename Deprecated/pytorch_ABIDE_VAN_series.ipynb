{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import ToTensor, Lambda\n",
    "import torchinfo\n",
    "\n",
    "import numpy as np\n",
    "import math\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Device:【cuda:None】\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU Device:【{}:{}】\".format(device.type, device.index))\n",
    "    torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data:np.ndarray, labels:np.ndarray, transform=ToTensor(), \n",
    "    target_transform=Lambda(lambda y: torch.zeros(2, dtype=torch.float).scatter_(dim=0, index=torch.tensor(y), value=1))):\n",
    "        self.data:torch.Tensor = torch.from_numpy(np.swapaxes(data, 1, 2))\n",
    "        self.labels:torch.Tensor = torch.from_numpy(labels)\n",
    "        self.transform = None\n",
    "        self.target_transform = None\n",
    "        # self.transform = transform\n",
    "        # self.target_transform = target_transform\n",
    "        # self.shuffle()\n",
    "    \n",
    "    def shuffle(self, seed=None):\n",
    "        '\\n        seed(self, seed=None)\\n\\n        Reseed a legacy MT19937 BitGenerator\\n        '\n",
    "        self.shuffle_seed = np.random.randint(1, 65535) if seed is None else seed\n",
    "        print(f\"随机种子：{self.shuffle_seed}\")\n",
    "        np.random.seed(self.shuffle_seed)\n",
    "        np.random.shuffle(self.data)\n",
    "        np.random.seed(self.shuffle_seed)\n",
    "        np.random.shuffle(self.labels)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data[idx]\n",
    "        label = self.labels[idx, 0]\n",
    "        if self.transform:\n",
    "            data = self.transform(data)\n",
    "        if self.target_transform:\n",
    "            label = self.target_transform(label)\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path=\"dataset.npz\", train_percent=0.8) -> tuple:\n",
    "    with np.load(path) as dataset:\n",
    "        full_data = dataset[\"data\"].astype(np.float32)\n",
    "        full_labels = dataset[\"labels\"].astype(np.int64)\n",
    "    train_size = int(full_data.shape[0]*train_percent)\n",
    "    test_size = full_data.shape[0]-train_size\n",
    "    seed = np.random.randint(1, 65535) # 35468\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(full_data)\n",
    "    np.random.seed(seed)\n",
    "    np.random.shuffle(full_labels)\n",
    "    train_data, test_data = full_data[:train_size], full_data[train_size:]\n",
    "    train_labels, test_labels = full_labels[:train_size], full_labels[train_size:]\n",
    "    print(f\"训练集大小：{train_size}\", f\"测试集大小：{test_size}\", f\"随机种子：{seed}\")\n",
    "    train_dataset = CustomDataset(train_data, train_labels)\n",
    "    test_dataset = CustomDataset(test_data, test_labels)\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小：9636 测试集大小：2409 随机种子：12160\n"
     ]
    }
   ],
   "source": [
    "train_dataset, test_dataset = load_dataset(\"D:\\\\datasets\\\\ABIDE\\\\ABIDE_augmented_dataset.npz\", 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X [N, L, H]: torch.Size([64, 116, 60])\n",
      "Shape of y: torch.Size([64]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "batch_size=64\n",
    "\n",
    "# Create data loaders.\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    data_shape = X.shape\n",
    "    label_shape = y.shape\n",
    "    print(f\"Shape of X [N, L, H]: {X.shape}\")\n",
    "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DWConv(nn.Module):\n",
    "    def __init__(self, dim=768):\n",
    "        super(DWConv, self).__init__()\n",
    "        self.dwconv = nn.Conv1d(dim, dim, 3, 1, 1, bias=True, groups=dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.dwconv(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LKA(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.conv0 = nn.Conv1d(dim, dim, 5, padding=2, groups=dim)\n",
    "        self.conv_spatial = nn.Conv1d(dim, dim, 7, stride=1, padding=9, groups=dim, dilation=3)\n",
    "        self.conv1 = nn.Conv1d(dim, dim, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        u = x.clone()        \n",
    "        attn = self.conv0(x)\n",
    "        attn = self.conv_spatial(attn)\n",
    "        attn = self.conv1(attn)\n",
    "\n",
    "        return u * attn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mlp(nn.Module):\n",
    "    def __init__(self, in_features, hidden_features=None, out_features=None, act_layer=nn.GELU, drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Conv1d(in_features, hidden_features, 1)\n",
    "        self.dwconv = DWConv(hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Conv1d(hidden_features, out_features, 1)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.dwconv(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, d_model):\n",
    "        super().__init__()\n",
    "\n",
    "        self.proj_1 = nn.Conv1d(d_model, d_model, 1)\n",
    "        self.activation = nn.GELU()\n",
    "        self.spatial_gating_unit = LKA(d_model)\n",
    "        self.proj_2 = nn.Conv1d(d_model, d_model, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shorcut = x.clone()\n",
    "        x = self.proj_1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.spatial_gating_unit(x)\n",
    "        x = self.proj_2(x)\n",
    "        x = x + shorcut\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Block(nn.Module):\n",
    "    def __init__(self, dim, mlp_ratio=4., drop=0., act_layer=nn.GELU):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.BatchNorm1d(dim)\n",
    "        self.attn = Attention(dim)\n",
    "\n",
    "        self.norm2 = nn.BatchNorm1d(dim)\n",
    "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
    "        self.mlp = Mlp(in_features=dim, hidden_features=mlp_hidden_dim, act_layer=act_layer, drop=drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(x)\n",
    "        x = x + self.mlp(x)\n",
    "        # x = x + self.attn(self.norm1(x))\n",
    "        # x = x + self.mlp(self.norm2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OverlapPatchEmbed(nn.Module):\n",
    "    \"\"\" Image to Patch Embedding\n",
    "    \"\"\"\n",
    "    def __init__(self, img_size=224, patch_size=7, stride=4, in_chans=3, embed_dim=768):\n",
    "        super().__init__()\n",
    "        self.proj = nn.Conv1d(in_chans, embed_dim, kernel_size=patch_size, stride=stride,\n",
    "                              padding=patch_size//2)\n",
    "        self.norm = nn.BatchNorm1d(embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "        _, L, H = x.shape\n",
    "        # x = self.norm(x)\n",
    "        return x, L, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAN(nn.Module):\n",
    "    def __init__(self, img_size=224, in_chans=3, num_classes=1000, embed_dims=[64, 128, 256, 512],\n",
    "                mlp_ratios=[4, 4, 4, 4], drop_rate=0., norm_layer=nn.LayerNorm,\n",
    "                 depths=[3, 4, 6, 3], num_stages=4, device=torch.device(\"cuda\")):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.depths = depths\n",
    "        self.num_stages = num_stages\n",
    "\n",
    "        for i in range(num_stages):\n",
    "            patch_embed = OverlapPatchEmbed(img_size=img_size if i == 0 else img_size // (2 ** (i + 1)),\n",
    "                                            patch_size=7 if i == 0 else 3,\n",
    "                                            stride=4 if i == 0 else 2,\n",
    "                                            in_chans=in_chans if i == 0 else embed_dims[i - 1],\n",
    "                                            embed_dim=embed_dims[i])\n",
    "\n",
    "            block = nn.ModuleList([Block(dim=embed_dims[i], mlp_ratio=mlp_ratios[i], drop=drop_rate)\n",
    "                for j in range(depths[i])])\n",
    "            norm = norm_layer(embed_dims[i])\n",
    "\n",
    "            setattr(self, f\"patch_embed{i + 1}\", patch_embed)\n",
    "            setattr(self, f\"block{i + 1}\", block)\n",
    "            setattr(self, f\"norm{i + 1}\", norm)\n",
    "\n",
    "        # classification head\n",
    "        self.head = nn.Linear(embed_dims[3], num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.trunc_normal_(m.weight, std=.02)\n",
    "            if isinstance(m, nn.Linear) and m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv1d):\n",
    "            fan_out = m.kernel_size[0] * m.out_channels\n",
    "            fan_out //= m.groups\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        B = x.shape[0]\n",
    "\n",
    "        for i in range(self.num_stages):\n",
    "            patch_embed = getattr(self, f\"patch_embed{i + 1}\")\n",
    "            block = getattr(self, f\"block{i + 1}\")\n",
    "            norm = getattr(self, f\"norm{i + 1}\")\n",
    "            x, L, H = patch_embed(x)\n",
    "            for blk in block:\n",
    "                x = blk(x)\n",
    "            x = x.flatten(2).transpose(1, 2)\n",
    "            x = norm(x)\n",
    "            if i != self.num_stages - 1:\n",
    "                x = x.reshape(B, H, -1).permute(0, 2, 1).contiguous()\n",
    "\n",
    "        return x.mean(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyVAN(nn.Module):\n",
    "    def __init__(self, img_size=224, in_chans=3, num_classes=1000, embed_dims=[64, 128, 256, 512],\n",
    "                mlp_ratios=[4, 4, 4, 4], drop_rate=0., norm_layer=nn.LayerNorm,\n",
    "                 depths=[3, 4, 6, 3], num_stages=4, device=torch.device(\"cuda\")):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "        self.depths = depths\n",
    "        self.num_stages = num_stages\n",
    "\n",
    "        self.device:torch.DeviceObjType = device\n",
    "        # self.cache:bool = cache\n",
    "        # self.__cache:list(torch.TensorType) = []\n",
    "        # self.copy_block:bool = copy_block\n",
    "        \n",
    "        self._embed_dims = embed_dims\n",
    "        self._mlp_ratios = mlp_ratios\n",
    "        self.drop_rate = drop_rate\n",
    "\n",
    "        for i in range(num_stages):\n",
    "            patch_embed = OverlapPatchEmbed(img_size=img_size if i == 0 else img_size // (2 ** (i + 1)),\n",
    "                                            patch_size=7 if i == 0 else 3,\n",
    "                                            stride=4 if i == 0 else 2,\n",
    "                                            in_chans=in_chans if i == 0 else embed_dims[i - 1],\n",
    "                                            embed_dim=embed_dims[i])\n",
    "\n",
    "            block = nn.ModuleList([Block(dim=embed_dims[i], mlp_ratio=mlp_ratios[i], drop=drop_rate)])\n",
    "            norm = norm_layer(embed_dims[i])\n",
    "\n",
    "            setattr(self, f\"patch_embed{i + 1}\", patch_embed)\n",
    "            setattr(self, f\"block{i + 1}\", block)\n",
    "            setattr(self, f\"norm{i + 1}\", norm)\n",
    "\n",
    "        # classification head\n",
    "        self.head = nn.Linear(embed_dims[3], num_classes) if num_classes > 0 else nn.Identity()\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "        self._block_full = False\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.trunc_normal_(m.weight, std=.02)\n",
    "            if m.bias is not None:\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, nn.LayerNorm):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "        elif isinstance(m, nn.Conv1d):\n",
    "            fan_out = m.kernel_size[0] * m.out_channels\n",
    "            fan_out //= m.groups\n",
    "            m.weight.data.normal_(0, math.sqrt(2.0 / fan_out))\n",
    "            if m.bias is not None:\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        # B = x.shape[0]\n",
    "\n",
    "        for i in range(self.num_stages):\n",
    "            patch_embed = getattr(self, f\"patch_embed{i + 1}\")\n",
    "            block = getattr(self, f\"block{i + 1}\")\n",
    "            norm = getattr(self, f\"norm{i + 1}\")\n",
    "            x, L, H = patch_embed(x)\n",
    "            for blk in block:\n",
    "                x = blk(x)\n",
    "            x = x.transpose(1, 2)\n",
    "            x = norm(x)\n",
    "            if i != self.num_stages - 1:\n",
    "                x = x.transpose(2, 1)\n",
    "\n",
    "        return x.mean(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def freeze(self, block:Block):\n",
    "        for param in block.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    # def __forward_cache(self, block):\n",
    "    #     if self.cache:\n",
    "    #         for batch, X in enumerate(self.__cache):\n",
    "    #             self.__cache[batch] = block(X.to(self.device))\n",
    "\n",
    "    def addNewBlock(self, copy_last=False):\n",
    "        if self._block_full:\n",
    "            return\n",
    "        print(\"----------\")\n",
    "        print(f\"{'Copying' if copy_last else 'Adding'} new block...\")\n",
    "        cnt = 0\n",
    "        for i in range(self.num_stages):\n",
    "            blocks:nn.ModuleList = getattr(self, f\"block{i + 1}\")\n",
    "            if len(blocks) >= self.depths[i]:\n",
    "                continue\n",
    "            newBlock = Block(self._embed_dims[i], self._mlp_ratios[i], self.drop_rate)\n",
    "            last_block:Block = blocks[-1]\n",
    "            if copy_last:\n",
    "                newBlock.load_state_dict(last_block.state_dict())\n",
    "            blocks.append(newBlock)\n",
    "            cnt += 1\n",
    "            self.freeze(last_block)\n",
    "            newBlock.to(self.device)\n",
    "        # self.__forward_cache(last_block)\n",
    "        if cnt == 0:\n",
    "            self._block_full = True\n",
    "        print(\"Success!\" if cnt else \"Full!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model:nn.Module, dataloader:DataLoader, loss_fn, device=torch.device(\"cuda\")):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    # model.train()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model.forward(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"-- Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model:nn.Module, train_dataloader:DataLoader, loss_fn, optimizer,\n",
    "    batch_size:int, epochs:int, add_new_block=False, copy_block=False, use_cache=False, device=torch.device(\"cuda\"), test_dataloader:DataLoader=None):\n",
    "    for X, y in train_dataloader:\n",
    "        data_shape = X.shape\n",
    "        label_shape = y.shape\n",
    "        break\n",
    "    size = len(train_dataloader.dataset)\n",
    "    num_batches = len(train_dataloader)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        print(f\"Epoch: {epoch+1}/{epochs}\")\n",
    "        if add_new_block and epoch and epoch%5 == 0:\n",
    "            model.addNewBlock(copy_block)\n",
    "        loss, correct = 0, 0\n",
    "        torch.cuda.synchronize()\n",
    "        time_delta = 0\n",
    "        for batch, (X, y) in enumerate(train_dataloader):\n",
    "            time_start = time.time()\n",
    "            if use_cache:\n",
    "                if epoch == 0:\n",
    "                    model.__cache.append(X)\n",
    "                X = model.__cache[batch].to(device)\n",
    "            else:\n",
    "                X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            # Compute prediction error\n",
    "            pred = model.forward(X)\n",
    "            batch_loss = loss_fn(pred, y)\n",
    "\n",
    "            # Backpropagation\n",
    "            batch_loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            current = batch * batch_size + len(X)\n",
    "\n",
    "            batch_loss = batch_loss.item()\n",
    "            loss += batch_loss\n",
    "            batch_correct = (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "            correct += batch_correct\n",
    "\n",
    "            batch_correct /= len(X)\n",
    "            # time_batch_end = time.time()\n",
    "            torch.cuda.synchronize()\n",
    "            time_end = time.time()\n",
    "            time_delta += (time_end - time_start)\n",
    "            print(f\"\\r{batch+1}/{num_batches}  [{current:>3d}/{size:>3d}] - batch loss: {batch_loss:>7f} - batch accuracy: {(100*batch_correct):>0.1f}% - {time_delta/(batch+1)*1000:>0.3f}ms/batch\", end = \"\", flush=True)\n",
    "        loss /= num_batches\n",
    "        correct /= size\n",
    "        torch.cuda.synchronize()\n",
    "        time_end = time.time()\n",
    "        print(f\"\\n-- Average loss: {loss:>7f} - Accuracy: {(100*correct):>0.1f}% - {time_delta*1000:>0.3f}ms\")\n",
    "        if test_dataloader is not None:\n",
    "            test(model, test_dataloader, loss_fn, device)\n",
    "    print(\"\\n\", torchinfo.summary(model, input_size=data_shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-4\n",
    "epochs = 5\n",
    "# loss_fn = nn.CrossEntropyLoss\n",
    "# optimizer = torch.optim.Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5\n",
      "151/151  [9636/9636] - batch loss:     nan - batch accuracy: 44.4% - 125.596ms/batch\n",
      "-- Average loss:     nan - Accuracy: 45.9% - 18964.998ms\n",
      "-- Test Error: \n",
      " Accuracy: 46.0%, Avg loss:      nan \n",
      "\n",
      "Epoch: 2/5\n",
      "151/151  [9636/9636] - batch loss:     nan - batch accuracy: 44.4% - 87.690ms/batch\n",
      "-- Average loss:     nan - Accuracy: 45.9% - 13241.205ms\n",
      "-- Test Error: \n",
      " Accuracy: 46.0%, Avg loss:      nan \n",
      "\n",
      "Epoch: 3/5\n",
      "151/151  [9636/9636] - batch loss:     nan - batch accuracy: 44.4% - 85.251ms/batch\n",
      "-- Average loss:     nan - Accuracy: 45.9% - 12872.850ms\n",
      "-- Test Error: \n",
      " Accuracy: 46.0%, Avg loss:      nan \n",
      "\n",
      "Epoch: 4/5\n",
      "151/151  [9636/9636] - batch loss:     nan - batch accuracy: 44.4% - 85.495ms/batch\n",
      "-- Average loss:     nan - Accuracy: 45.9% - 12909.799ms\n",
      "-- Test Error: \n",
      " Accuracy: 46.0%, Avg loss:      nan \n",
      "\n",
      "Epoch: 5/5\n",
      "151/151  [9636/9636] - batch loss:     nan - batch accuracy: 44.4% - 91.233ms/batch\n",
      "-- Average loss:     nan - Accuracy: 45.9% - 13776.193ms\n",
      "-- Test Error: \n",
      " Accuracy: 46.0%, Avg loss:      nan \n",
      "\n",
      "\n",
      " ==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "VAN                                      --                        --\n",
      "├─ModuleList: 1-1                        --                        --\n",
      "├─ModuleList: 1-2                        --                        --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "├─ModuleList: 1-4                        --                        --\n",
      "├─OverlapPatchEmbed: 1-5                 [64, 64, 15]              --\n",
      "│    └─Conv1d: 2-1                       [64, 64, 15]              52,032\n",
      "├─ModuleList: 1-1                        --                        --\n",
      "│    └─Block: 2-2                        [64, 64, 15]              --\n",
      "│    │    └─Attention: 3-1               [64, 64, 15]              13,376\n",
      "│    │    └─Mlp: 3-2                     [64, 64, 15]              34,112\n",
      "│    └─Block: 2-3                        [64, 64, 15]              --\n",
      "│    │    └─Attention: 3-3               [64, 64, 15]              13,376\n",
      "│    │    └─Mlp: 3-4                     [64, 64, 15]              34,112\n",
      "│    └─Block: 2-4                        [64, 64, 15]              --\n",
      "│    │    └─Attention: 3-5               [64, 64, 15]              13,376\n",
      "│    │    └─Mlp: 3-6                     [64, 64, 15]              34,112\n",
      "├─LayerNorm: 1-6                         [64, 15, 64]              128\n",
      "├─OverlapPatchEmbed: 1-7                 [64, 128, 8]              --\n",
      "│    └─Conv1d: 2-5                       [64, 128, 8]              24,704\n",
      "├─ModuleList: 1-2                        --                        --\n",
      "│    └─Block: 2-6                        [64, 128, 8]              --\n",
      "│    │    └─Attention: 3-7               [64, 128, 8]              51,328\n",
      "│    │    └─Mlp: 3-8                     [64, 128, 8]              133,760\n",
      "│    └─Block: 2-7                        [64, 128, 8]              --\n",
      "│    │    └─Attention: 3-9               [64, 128, 8]              51,328\n",
      "│    │    └─Mlp: 3-10                    [64, 128, 8]              133,760\n",
      "│    └─Block: 2-8                        [64, 128, 8]              --\n",
      "│    │    └─Attention: 3-11              [64, 128, 8]              51,328\n",
      "│    │    └─Mlp: 3-12                    [64, 128, 8]              133,760\n",
      "│    └─Block: 2-9                        [64, 128, 8]              --\n",
      "│    │    └─Attention: 3-13              [64, 128, 8]              51,328\n",
      "│    │    └─Mlp: 3-14                    [64, 128, 8]              133,760\n",
      "├─LayerNorm: 1-8                         [64, 8, 128]              256\n",
      "├─OverlapPatchEmbed: 1-9                 [64, 256, 4]              --\n",
      "│    └─Conv1d: 2-10                      [64, 256, 4]              98,560\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─Block: 2-11                       [64, 256, 4]              --\n",
      "│    │    └─Attention: 3-15              [64, 256, 4]              200,960\n",
      "│    │    └─Mlp: 3-16                    [64, 256, 4]              529,664\n",
      "│    └─Block: 2-12                       [64, 256, 4]              --\n",
      "│    │    └─Attention: 3-17              [64, 256, 4]              200,960\n",
      "│    │    └─Mlp: 3-18                    [64, 256, 4]              529,664\n",
      "│    └─Block: 2-13                       [64, 256, 4]              --\n",
      "│    │    └─Attention: 3-19              [64, 256, 4]              200,960\n",
      "│    │    └─Mlp: 3-20                    [64, 256, 4]              529,664\n",
      "│    └─Block: 2-14                       [64, 256, 4]              --\n",
      "│    │    └─Attention: 3-21              [64, 256, 4]              200,960\n",
      "│    │    └─Mlp: 3-22                    [64, 256, 4]              529,664\n",
      "│    └─Block: 2-15                       [64, 256, 4]              --\n",
      "│    │    └─Attention: 3-23              [64, 256, 4]              200,960\n",
      "│    │    └─Mlp: 3-24                    [64, 256, 4]              529,664\n",
      "│    └─Block: 2-16                       [64, 256, 4]              --\n",
      "│    │    └─Attention: 3-25              [64, 256, 4]              200,960\n",
      "│    │    └─Mlp: 3-26                    [64, 256, 4]              529,664\n",
      "├─LayerNorm: 1-10                        [64, 4, 256]              512\n",
      "├─OverlapPatchEmbed: 1-11                [64, 512, 2]              --\n",
      "│    └─Conv1d: 2-17                      [64, 512, 2]              393,728\n",
      "├─ModuleList: 1-4                        --                        --\n",
      "│    └─Block: 2-18                       [64, 512, 2]              --\n",
      "│    │    └─Attention: 3-27              [64, 512, 2]              795,136\n",
      "│    │    └─Mlp: 3-28                    [64, 512, 2]              2,107,904\n",
      "│    └─Block: 2-19                       [64, 512, 2]              --\n",
      "│    │    └─Attention: 3-29              [64, 512, 2]              795,136\n",
      "│    │    └─Mlp: 3-30                    [64, 512, 2]              2,107,904\n",
      "│    └─Block: 2-20                       [64, 512, 2]              --\n",
      "│    │    └─Attention: 3-31              [64, 512, 2]              795,136\n",
      "│    │    └─Mlp: 3-32                    [64, 512, 2]              2,107,904\n",
      "├─LayerNorm: 1-12                        [64, 2, 512]              1,024\n",
      "├─Linear: 1-13                           [64, 2]                   1,026\n",
      "==========================================================================================\n",
      "Total params: 14,547,650\n",
      "Trainable params: 14,547,650\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 2.89\n",
      "==========================================================================================\n",
      "Input size (MB): 1.78\n",
      "Forward/backward pass size (MB): 120.19\n",
      "Params size (MB): 58.19\n",
      "Estimated Total Size (MB): 180.17\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "model = VAN(data_shape[2], data_shape[1], 2, device=device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=lr)\n",
    "model.to(device)\n",
    "train(model, train_dataloader, loss_fn, optimizer, batch_size, epochs, device=device, test_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/5\n",
      "151/151  [9636/9636] - batch loss: 0.689021 - batch accuracy: 44.4% - 30.926ms/batch\n",
      "-- Average loss: 0.706649 - Accuracy: 51.9% - 4669.848ms\n",
      "-- Test Error: \n",
      " Accuracy: 50.5%, Avg loss: 0.695382 \n",
      "\n",
      "Epoch: 2/5\n",
      "151/151  [9636/9636] - batch loss: 0.542509 - batch accuracy: 72.2% - 30.747ms/batch\n",
      "-- Average loss: 0.621162 - Accuracy: 65.7% - 4642.832ms\n",
      "-- Test Error: \n",
      " Accuracy: 49.9%, Avg loss: 0.747441 \n",
      "\n",
      "Epoch: 3/5\n",
      "151/151  [9636/9636] - batch loss: 0.113019 - batch accuracy: 97.2% - 31.039ms/batch\n",
      "-- Average loss: 0.302967 - Accuracy: 88.1% - 4686.888ms\n",
      "-- Test Error: \n",
      " Accuracy: 50.4%, Avg loss: 1.130643 \n",
      "\n",
      "Epoch: 4/5\n",
      "151/151  [9636/9636] - batch loss: 0.052794 - batch accuracy: 97.2% - 29.460ms/batchh\n",
      "-- Average loss: 0.157281 - Accuracy: 93.8% - 4448.464ms\n",
      "-- Test Error: \n",
      " Accuracy: 49.9%, Avg loss: 1.350594 \n",
      "\n",
      "Epoch: 5/5\n",
      "151/151  [9636/9636] - batch loss: 0.045421 - batch accuracy: 100.0% - 29.060ms/batch\n",
      "-- Average loss: 0.152261 - Accuracy: 93.8% - 4388.016ms\n",
      "-- Test Error: \n",
      " Accuracy: 52.2%, Avg loss: 1.509564 \n",
      "\n",
      "\n",
      " ==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "MyVAN                                    --                        --\n",
      "├─ModuleList: 1-1                        --                        --\n",
      "├─ModuleList: 1-2                        --                        --\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "├─ModuleList: 1-4                        --                        --\n",
      "├─OverlapPatchEmbed: 1-5                 [64, 64, 15]              --\n",
      "│    └─Conv1d: 2-1                       [64, 64, 15]              52,032\n",
      "├─ModuleList: 1-1                        --                        --\n",
      "│    └─Block: 2-2                        [64, 64, 15]              --\n",
      "│    │    └─Attention: 3-1               [64, 64, 15]              13,376\n",
      "│    │    └─Mlp: 3-2                     [64, 64, 15]              34,112\n",
      "├─LayerNorm: 1-6                         [64, 15, 64]              128\n",
      "├─OverlapPatchEmbed: 1-7                 [64, 128, 8]              --\n",
      "│    └─Conv1d: 2-3                       [64, 128, 8]              24,704\n",
      "├─ModuleList: 1-2                        --                        --\n",
      "│    └─Block: 2-4                        [64, 128, 8]              --\n",
      "│    │    └─Attention: 3-3               [64, 128, 8]              51,328\n",
      "│    │    └─Mlp: 3-4                     [64, 128, 8]              133,760\n",
      "├─LayerNorm: 1-8                         [64, 8, 128]              256\n",
      "├─OverlapPatchEmbed: 1-9                 [64, 256, 4]              --\n",
      "│    └─Conv1d: 2-5                       [64, 256, 4]              98,560\n",
      "├─ModuleList: 1-3                        --                        --\n",
      "│    └─Block: 2-6                        [64, 256, 4]              --\n",
      "│    │    └─Attention: 3-5               [64, 256, 4]              200,960\n",
      "│    │    └─Mlp: 3-6                     [64, 256, 4]              529,664\n",
      "├─LayerNorm: 1-10                        [64, 4, 256]              512\n",
      "├─OverlapPatchEmbed: 1-11                [64, 512, 2]              --\n",
      "│    └─Conv1d: 2-7                       [64, 512, 2]              393,728\n",
      "├─ModuleList: 1-4                        --                        --\n",
      "│    └─Block: 2-8                        [64, 512, 2]              --\n",
      "│    │    └─Attention: 3-7               [64, 512, 2]              795,136\n",
      "│    │    └─Mlp: 3-8                     [64, 512, 2]              2,107,904\n",
      "├─LayerNorm: 1-12                        [64, 2, 512]              1,024\n",
      "├─Linear: 1-13                           [64, 2]                   1,026\n",
      "==========================================================================================\n",
      "Total params: 4,438,210\n",
      "Trainable params: 4,438,210\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 837.40\n",
      "==========================================================================================\n",
      "Input size (MB): 1.78\n",
      "Forward/backward pass size (MB): 33.03\n",
      "Params size (MB): 17.75\n",
      "Estimated Total Size (MB): 52.57\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "my_model = MyVAN(data_shape[2], data_shape[1], 2, device=device)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, my_model.parameters()), lr=lr)\n",
    "my_model.to(device)\n",
    "train(my_model, train_dataloader, loss_fn, optimizer, batch_size, epochs, add_new_block=True, copy_block=True, device=device, test_dataloader=test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Test Error: \n",
      " Accuracy: 45.9%, Avg loss:      nan \n",
      "\n",
      "-- Test Error: \n",
      " Accuracy: 98.2%, Avg loss: 0.056814 \n",
      "\n",
      "-- Test Error: \n",
      " Accuracy: 46.0%, Avg loss:      nan \n",
      "\n",
      "-- Test Error: \n",
      " Accuracy: 52.2%, Avg loss: 1.509564 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(model, train_dataloader, loss_fn, device=device)\n",
    "test(my_model, train_dataloader, loss_fn, device=device)\n",
    "\n",
    "test(model, test_dataloader, loss_fn, device=device)\n",
    "test(my_model, test_dataloader, loss_fn, device=device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "240bc028caeb8b02ff80d8aedfc61caf7a0e4db2770780d40c5b717508bae340"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
