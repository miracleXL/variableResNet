{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import types\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import Model, layers\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import datetime\n",
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir = \"logs/fit/\" + current_time\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "# test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
    "# train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "# test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpus[0], True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load images dataset\n",
    "def load_dataset(name:str=\"mnist\", size:int=-1):\n",
    "    if name == \"mnist\":\n",
    "        (train_x, train_y), (test_x, test_y) = keras.datasets.mnist.load_data()\n",
    "    elif name == \"cifar10\":\n",
    "        (train_x, train_y), (test_x, test_y) = keras.datasets.cifar10.load_data()\n",
    "    train_x, test_x = train_x/255.0, test_x/255.0\n",
    "\n",
    "    train_x = train_x[:size][..., tf.newaxis].astype(\"float32\")\n",
    "    test_x = test_x[:size][..., tf.newaxis].astype(\"float32\")\n",
    "    train_y, test_y = train_y[:size], test_y[:size]\n",
    "    return (train_x, train_y), (test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=32\n",
    "epochs=30\n",
    "(train_x, train_y), (test_x, test_y) = load_dataset(\"cifar10\", size=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResBlock(layers.Layer):\n",
    "\n",
    "    def __init__(self, *args, **wargs):\n",
    "        super().__init__(*args, **wargs)\n",
    "        self.conv = layers.Conv2D(64, 3, padding=\"same\", activation=\"relu\")\n",
    "        self.bn = layers.BatchNormalization()\n",
    "        self.downconv = layers.Conv2D(64, 1, padding=\"same\")\n",
    "        self.downbn = layers.BatchNormalization()\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        # resolve output shape in model summary\n",
    "        input_layer = layers.Input(shape=input_shape[1:], batch_size=input_shape[0])\n",
    "        self.call(input_layer)\n",
    "        return super().build(input_shape)\n",
    "\n",
    "    def call(self, inputs:np.ndarray):\n",
    "        x:np.ndarray = inputs\n",
    "        fx:np.ndarray = x\n",
    "        fx = self.conv(fx)\n",
    "        fx = self.bn(fx)\n",
    "        if fx.shape[-1] != x.shape[-1]:\n",
    "            x = self.downconv(x)\n",
    "            x = self.downbn(x)\n",
    "        try:\n",
    "            # print(self.name, x.shape, fx.shape, inputs.shape)\n",
    "            return fx + x\n",
    "        except:\n",
    "            raise RuntimeError(x.shape, fx.shape, inputs.shape)\n",
    "\n",
    "    # def get_weights(self):\n",
    "    #     return [self.conv.get_weights(), self.bn.get_weights()]\n",
    "\n",
    "    # def set_weights(self, weights:list):\n",
    "    #     self.conv.set_weights(weights[0])\n",
    "    #     self.bn.set_weights(weights[1])\n",
    "    #     return super().set_weights(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyResNet(Model):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.__blocks_num = 1\n",
    "        self.__frozen_blocks_num = 0\n",
    "        # An ordinary ResNet, but put blocks in a list. New blocks will be added into this list when training.\n",
    "        # 常规的残差网络，但将残差块放在一个list中，训练时会将新块添加到这里\n",
    "        self.blocks = [ResBlock(name=\"res_block0\")]\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dense = layers.Dense(10)\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        # resolve output shape in model summary\n",
    "        input_layer = layers.Input(shape=input_shape[1:], batch_size=input_shape[0])\n",
    "        self.call(input_layer)\n",
    "        return super().build(input_shape)\n",
    "\n",
    "    def call(self, x=None, training=None, mask=None):\n",
    "        for i in range(self.__blocks_num):\n",
    "            x = self.blocks[i](x, training=training)\n",
    "        x = self.flatten(x, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "        return x\n",
    "\n",
    "    def getBlocksNum(self):\n",
    "        return self.__blocks_num\n",
    "    \n",
    "    def freezeBlocks(self, num=1):\n",
    "        for i in range(self.__frozen_blocks_num, min(self.__frozen_blocks_num+num, self.__blocks_num)):\n",
    "            self.blocks[i].trainable = False\n",
    "        self.__frozen_blocks_num = min(self.__frozen_blocks_num+num, self.__blocks_num)\n",
    "        print(\"freeze blocks:\", num, \", total frozen blocks:\", self.__frozen_blocks_num)\n",
    "    \n",
    "    def addNewBlock(self):\n",
    "        print(\"----------\")\n",
    "        print(\"add new block\")\n",
    "        # self.freezeBlocks(1)\n",
    "        newBlock = ResBlock(name=\"res_block\"+str(self.__blocks_num))\n",
    "        newBlock(self.blocks[-1].output)\n",
    "        self.blocks.append(newBlock)\n",
    "        self.__blocks_num += 1\n",
    "    \n",
    "    def copyLastBlock(self):\n",
    "        print(\"----------\")\n",
    "        print(\"copy last block\")\n",
    "        # self.freezeBlocks(1)\n",
    "        newBlock = ResBlock(name=\"res_block\"+str(self.__blocks_num))\n",
    "        last_block:ResBlock = self.blocks[-1]\n",
    "        newBlock(last_block.output)\n",
    "        if last_block.input_shape == last_block.output_shape:\n",
    "            newBlock.set_weights(last_block.get_weights())\n",
    "        else:\n",
    "            print(\"copy failed: shape different with last block\")\n",
    "        self.blocks.append(newBlock)\n",
    "        self.__blocks_num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dynamicResNet:\n",
    "    def __init__(self, condition: types.FunctionType = None, max_blocks_num:int = 2, copy_last_block:bool = False,*args, **wargs) -> None:\n",
    "        \"\"\"\n",
    "            condition: A function, which will be called in every epoch and returns a boolean value representing whether to add a new block.\n",
    "                        一个函数，每个epoch会被调用一次，返回值为布尔类型，代表是否添加新的块\n",
    "        \"\"\"\n",
    "        super(dynamicResNet, self).__init__(*args, **wargs)\n",
    "        if condition is None:\n",
    "            self.add_condition = self.set_epochs\n",
    "            self.add_condition()\n",
    "        else:\n",
    "            if callable(condition):\n",
    "                self.add_condition = condition\n",
    "            else:\n",
    "                raise ValueError(\"'condition' must be a function\")\n",
    "        self.max_blocks_num = max_blocks_num\n",
    "        self.copy_last_block = copy_last_block\n",
    "        # build model //创建模型\n",
    "        self.model = MyResNet()\n",
    "        self.compiled = False\n",
    "\n",
    "    def compile(self,\n",
    "                optimizer=\"rmsprop\",\n",
    "                loss=None,\n",
    "                metrics=None,\n",
    "                loss_weights=None,\n",
    "                weighted_metrics=None,\n",
    "                run_eagerly=None,\n",
    "                steps_per_execution=None,\n",
    "                **kwargs\n",
    "    ):\n",
    "        self.complieArgs = [optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution]\n",
    "        self.complieKwargs = kwargs\n",
    "        self.model.compile(*self.complieArgs, **kwargs)\n",
    "        self.compiled = True\n",
    "\n",
    "    def fit(self,\n",
    "            x=None,\n",
    "            y=None,\n",
    "            batch_size=None,\n",
    "            epochs=1,\n",
    "            verbose=\"auto\",\n",
    "            callbacks=None,\n",
    "            validation_split=0.0,\n",
    "            validation_data=None,\n",
    "            shuffle=True,\n",
    "            class_weight=None,\n",
    "            sample_weight=None,\n",
    "            initial_epoch=0,\n",
    "            steps_per_epoch=None,\n",
    "            validation_steps=None,\n",
    "            validation_batch_size=None,\n",
    "            validation_freq=1,\n",
    "            max_queue_size=10,\n",
    "            workers=1,\n",
    "            use_multiprocessing=False\n",
    "    ):\n",
    "        if not self.compiled:\n",
    "            raise RuntimeError(\"model should be compiled before fit\")\n",
    "        self.epochs = epochs\n",
    "        self.fitArgs = [x,y,batch_size,1,verbose,callbacks,validation_split,validation_data,shuffle,class_weight,sample_weight,initial_epoch,steps_per_epoch,validation_steps,validation_batch_size,validation_freq,max_queue_size,workers,use_multiprocessing]\n",
    "        return self.call(training=True)\n",
    "    \n",
    "    def predict(self,\n",
    "                x,\n",
    "                batch_size=None,\n",
    "                verbose=\"auto\",\n",
    "                steps=None,\n",
    "                callbacks=None,\n",
    "                max_queue_size=10,\n",
    "                workers=1,\n",
    "                use_multiprocessing=False\n",
    "    ):\n",
    "        if not self.compiled:\n",
    "            raise RuntimeError(\"model should be compiled before predict\")\n",
    "        return self.model.predict( x,\n",
    "                                    batch_size=batch_size,\n",
    "                                    verbose=verbose,\n",
    "                                    steps=steps,\n",
    "                                    callbacks=callbacks,\n",
    "                                    max_queue_size=max_queue_size,\n",
    "                                    workers=workers,\n",
    "                                    use_multiprocessing=use_multiprocessing\n",
    "                                 )\n",
    "\n",
    "\n",
    "    def call(self, x=None, training=False):\n",
    "        if training:\n",
    "            if x:\n",
    "                raise ValueError(\"Please use 'fit' when training.\")\n",
    "            def fit_epoch():\n",
    "                # 满足条件动态添加新残差块\n",
    "                if self.model.getBlocksNum() < self.max_blocks_num and self.add_condition():\n",
    "                    self.model.freezeBlocks(1)\n",
    "                    if self.copy_last_block:\n",
    "                        self.model.copyLastBlock()\n",
    "                    else:\n",
    "                        self.model.addNewBlock()\n",
    "                    self.model.compile(*self.complieArgs, **self.complieKwargs)\n",
    "                self.model.fit(*self.fitArgs)\n",
    "            for epoch in range(self.epochs):\n",
    "                print(f\"Epoch {epoch+1}/{self.epochs}\")\n",
    "                # 使用多进程的方式可以释放显存\n",
    "                p = Thread(target=fit_epoch)\n",
    "                p.start()\n",
    "                p.join()\n",
    "        else:\n",
    "            return self.model.predict(x)\n",
    "\n",
    "    def set_epochs(self, interval_of_epochs:int = None) -> None:\n",
    "        self.epoch = 0\n",
    "        self.last_change_epoch = 1\n",
    "        if interval_of_epochs is None:\n",
    "            self.interval = 1\n",
    "        else:\n",
    "            self.interval = interval_of_epochs\n",
    "        self.add_condition = self.__num_of_epochs\n",
    "\n",
    "    def __num_of_epochs(self) -> bool:\n",
    "        self.epoch += 1\n",
    "        if self.epoch - self.last_change_epoch == self.interval:\n",
    "            self.last_change_epoch = self.epoch\n",
    "            return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method MyResNet.call of <__main__.MyResNet object at 0x000001C466FABCA0>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method MyResNet.call of <__main__.MyResNet object at 0x000001C466FABCA0>> and will run it as-is.\n",
      "Cause: mangled names are not yet supported\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "32/32 [==============================] - 6s 145ms/step - loss: 39.8797 - accuracy: 0.2160\n",
      "Epoch 2/30\n",
      "32/32 [==============================] - 5s 141ms/step - loss: 13.8447 - accuracy: 0.3990\n",
      "Epoch 3/30\n",
      "32/32 [==============================] - 4s 123ms/step - loss: 6.9734 - accuracy: 0.4980\n",
      "Epoch 4/30\n",
      "32/32 [==============================] - 4s 118ms/step - loss: 3.4534 - accuracy: 0.6010\n",
      "Epoch 5/30\n",
      "32/32 [==============================] - 4s 116ms/step - loss: 2.2986 - accuracy: 0.6990\n",
      "Epoch 6/30\n",
      "freeze blocks: 1 , total frozen blocks: 1\n",
      "add new block\n",
      "32/32 [==============================] - 7s 178ms/step - loss: 6.2591 - accuracy: 0.4860\n",
      "Epoch 7/30\n",
      "32/32 [==============================] - 6s 177ms/step - loss: 0.4338 - accuracy: 0.8560\n",
      "Epoch 8/30\n",
      "32/32 [==============================] - 6s 176ms/step - loss: 0.1469 - accuracy: 0.9610\n",
      "Epoch 9/30\n",
      "32/32 [==============================] - 6s 173ms/step - loss: 0.0640 - accuracy: 0.9860\n",
      "Epoch 10/30\n",
      "32/32 [==============================] - 6s 177ms/step - loss: 0.0460 - accuracy: 0.9900\n",
      "Epoch 11/30\n",
      "freeze blocks: 1 , total frozen blocks: 2\n",
      "add new block\n",
      "32/32 [==============================] - 8s 207ms/step - loss: 7.1834 - accuracy: 0.5920\n",
      "Epoch 12/30\n",
      "32/32 [==============================] - 7s 207ms/step - loss: 0.6182 - accuracy: 0.8820\n",
      "Epoch 13/30\n",
      "32/32 [==============================] - 7s 206ms/step - loss: 0.3067 - accuracy: 0.9430\n",
      "Epoch 14/30\n",
      "32/32 [==============================] - 8s 234ms/step - loss: 0.0934 - accuracy: 0.9740\n",
      "Epoch 15/30\n",
      "32/32 [==============================] - 7s 212ms/step - loss: 0.0173 - accuracy: 0.9970\n",
      "Epoch 16/30\n",
      "freeze blocks: 1 , total frozen blocks: 3\n",
      "add new block\n",
      "32/32 [==============================] - 9s 243ms/step - loss: 6.2749 - accuracy: 0.6620\n",
      "Epoch 17/30\n",
      "32/32 [==============================] - 8s 240ms/step - loss: 0.8650 - accuracy: 0.9000\n",
      "Epoch 18/30\n",
      "32/32 [==============================] - 8s 257ms/step - loss: 0.1952 - accuracy: 0.9670\n",
      "Epoch 19/30\n",
      "32/32 [==============================] - 9s 264ms/step - loss: 0.1719 - accuracy: 0.9750\n",
      "Epoch 20/30\n",
      "32/32 [==============================] - 8s 248ms/step - loss: 0.2150 - accuracy: 0.9780\n",
      "Epoch 21/30\n",
      "freeze blocks: 1 , total frozen blocks: 4\n",
      "add new block\n",
      "32/32 [==============================] - 10s 283ms/step - loss: 6.2803 - accuracy: 0.7130\n",
      "Epoch 22/30\n",
      "32/32 [==============================] - 9s 275ms/step - loss: 1.7906 - accuracy: 0.8900\n",
      "Epoch 23/30\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.7489 - accuracy: 0.9510\n",
      "Epoch 24/30\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.3033 - accuracy: 0.9770\n",
      "Epoch 25/30\n",
      "32/32 [==============================] - 9s 278ms/step - loss: 0.1967 - accuracy: 0.9850\n",
      "Epoch 26/30\n",
      "32/32 [==============================] - 9s 272ms/step - loss: 0.2579 - accuracy: 0.9750\n",
      "Epoch 27/30\n",
      "32/32 [==============================] - 9s 274ms/step - loss: 0.1518 - accuracy: 0.9870\n",
      "Epoch 28/30\n",
      "32/32 [==============================] - 9s 266ms/step - loss: 0.0515 - accuracy: 0.9940\n",
      "Epoch 29/30\n",
      "32/32 [==============================] - 9s 274ms/step - loss: 0.0946 - accuracy: 0.9920\n",
      "Epoch 30/30\n",
      "32/32 [==============================] - 9s 290ms/step - loss: 0.1721 - accuracy: 0.9870\n",
      "Model: \"my_res_net\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " res_block0 (ResBlock)       (None, 32, 32, 3, 64)     1280      \n",
      "                                                                 \n",
      " res_block1 (ResBlock)       (None, 32, 32, 3, 64)     37184     \n",
      "                                                                 \n",
      " res_block2 (ResBlock)       (None, 32, 32, 3, 64)     37184     \n",
      "                                                                 \n",
      " res_block3 (ResBlock)       (None, 32, 32, 3, 64)     37184     \n",
      "                                                                 \n",
      " res_block4 (ResBlock)       (None, 32, 32, 3, 64)     37184     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 196608)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 10)                1966090   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,116,106\n",
      "Trainable params: 2,003,146\n",
      "Non-trainable params: 112,960\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dynamic_model = dynamicResNet(max_blocks_num=5, copy_last_block=False)\n",
    "dynamic_model.set_epochs(5)\n",
    "def fit_dinamic_model():\n",
    "    dynamic_model.compile(optimizer=\"Adam\", loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "    dynamic_model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, callbacks=[tensorboard_callback])\n",
    "p = Thread(target=fit_dinamic_model)\n",
    "p.start()\n",
    "p.join()\n",
    "dynamic_model.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "32/32 [==============================] - 5s 117ms/step - loss: 41.8082 - accuracy: 0.2310\n",
      "Epoch 2/4\n",
      "freeze blocks: 1 , total frozen blocks: 1\n",
      "----------\n",
      "copy last block\n",
      "copy failed: shape different with last block\n",
      "32/32 [==============================] - 7s 180ms/step - loss: 11.6213 - accuracy: 0.2830\n",
      "Epoch 3/4\n",
      "freeze blocks: 1 , total frozen blocks: 2\n",
      "----------\n",
      "copy last block\n",
      "32/32 [==============================] - 8s 213ms/step - loss: 3.6602 - accuracy: 0.3650\n",
      "Epoch 4/4\n",
      "freeze blocks: 1 , total frozen blocks: 3\n",
      "----------\n",
      "copy last block\n",
      "32/32 [==============================] - 9s 242ms/step - loss: 2.2011 - accuracy: 0.4980\n",
      "Model: \"my_res_net_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " res_block0 (ResBlock)       (None, 32, 32, 3, 64)     1280      \n",
      "                                                                 \n",
      " res_block1 (ResBlock)       (None, 32, 32, 3, 64)     37184     \n",
      "                                                                 \n",
      " res_block2 (ResBlock)       (None, 32, 32, 3, 64)     37184     \n",
      "                                                                 \n",
      " res_block3 (ResBlock)       (None, 32, 32, 3, 64)     37184     \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 196608)            0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 10)                1966090   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,078,922\n",
      "Trainable params: 2,003,146\n",
      "Non-trainable params: 75,776\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "dynamic_model_copy = dynamicResNet(max_blocks_num=5, copy_last_block=True)\n",
    "dynamic_model_copy.set_epochs(5)\n",
    "\n",
    "def fit_dinamic_model():\n",
    "    dynamic_model_copy.compile(optimizer=\"Adam\", loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "    dynamic_model_copy.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, callbacks=[tensorboard_callback])\n",
    "\n",
    "p = Thread(target=fit_dinamic_model)\n",
    "p.start()\n",
    "p.join()\n",
    "dynamic_model_copy.model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1563/1563 [==============================] - 197s 124ms/step - loss: 8.0938 - accuracy: 0.3576\n",
      "Epoch 2/30\n",
      "1563/1563 [==============================] - 195s 125ms/step - loss: 3.3911 - accuracy: 0.4651\n",
      "Epoch 3/30\n",
      "1563/1563 [==============================] - 196s 126ms/step - loss: 2.9441 - accuracy: 0.5251\n",
      "Epoch 4/30\n",
      "1563/1563 [==============================] - 197s 126ms/step - loss: 2.5116 - accuracy: 0.5914\n",
      "Epoch 5/30\n",
      "1563/1563 [==============================] - 197s 126ms/step - loss: 2.1769 - accuracy: 0.6422\n",
      "Epoch 6/30\n",
      "1563/1563 [==============================] - 196s 126ms/step - loss: 1.8361 - accuracy: 0.6970\n",
      "Epoch 7/30\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 1.5757 - accuracy: 0.7397\n",
      "Epoch 8/30\n",
      "1563/1563 [==============================] - 192s 123ms/step - loss: 1.3799 - accuracy: 0.7709\n",
      "Epoch 9/30\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 1.2000 - accuracy: 0.8016\n",
      "Epoch 10/30\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 1.0702 - accuracy: 0.8231\n",
      "Epoch 11/30\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.9564 - accuracy: 0.8434\n",
      "Epoch 12/30\n",
      "1563/1563 [==============================] - 190s 122ms/step - loss: 0.8682 - accuracy: 0.8612\n",
      "Epoch 13/30\n",
      "1563/1563 [==============================] - 189s 121ms/step - loss: 0.8415 - accuracy: 0.8694\n",
      "Epoch 14/30\n",
      "1563/1563 [==============================] - 190s 122ms/step - loss: 0.7054 - accuracy: 0.8867\n",
      "Epoch 15/30\n",
      "1563/1563 [==============================] - 189s 121ms/step - loss: 0.6670 - accuracy: 0.8968\n",
      "Epoch 16/30\n",
      "1563/1563 [==============================] - 190s 122ms/step - loss: 0.6687 - accuracy: 0.9021\n",
      "Epoch 17/30\n",
      "1563/1563 [==============================] - 189s 121ms/step - loss: 0.5937 - accuracy: 0.9085\n",
      "Epoch 18/30\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.5519 - accuracy: 0.9173\n",
      "Epoch 19/30\n",
      "1563/1563 [==============================] - 189s 121ms/step - loss: 0.5610 - accuracy: 0.9195\n",
      "Epoch 20/30\n",
      "1563/1563 [==============================] - 189s 121ms/step - loss: 0.5109 - accuracy: 0.9268\n",
      "Epoch 21/30\n",
      "1563/1563 [==============================] - 190s 121ms/step - loss: 0.4995 - accuracy: 0.9306\n",
      "Epoch 22/30\n",
      "1563/1563 [==============================] - 190s 122ms/step - loss: 0.4671 - accuracy: 0.9358\n",
      "Epoch 23/30\n",
      "1563/1563 [==============================] - 193s 123ms/step - loss: 0.4569 - accuracy: 0.9377\n",
      "Epoch 24/30\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.4390 - accuracy: 0.9413\n",
      "Epoch 25/30\n",
      "1563/1563 [==============================] - 193s 123ms/step - loss: 0.4163 - accuracy: 0.9449\n",
      "Epoch 26/30\n",
      "1563/1563 [==============================] - 195s 125ms/step - loss: 0.4165 - accuracy: 0.9455\n",
      "Epoch 27/30\n",
      "1563/1563 [==============================] - 194s 124ms/step - loss: 0.3995 - accuracy: 0.9489\n",
      "Epoch 28/30\n",
      "1563/1563 [==============================] - 191s 122ms/step - loss: 0.3859 - accuracy: 0.9509\n",
      "Epoch 29/30\n",
      "1563/1563 [==============================] - 190s 121ms/step - loss: 0.3697 - accuracy: 0.9532\n",
      "Epoch 30/30\n",
      "1563/1563 [==============================] - 189s 121ms/step - loss: 0.3722 - accuracy: 0.9531\n"
     ]
    }
   ],
   "source": [
    "from keras import Sequential\n",
    "static_model = Sequential([ResBlock(), ResBlock(), ResBlock(), ResBlock(), ResBlock(), layers.Flatten(), layers.Dense(10)])\n",
    "def fit_static_model():\n",
    "    static_model.compile(optimizer=\"Adam\", loss=keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=[\"accuracy\"])\n",
    "    static_model.fit(train_x, train_y, batch_size=batch_size, epochs=epochs, callbacks=[tensorboard_callback])\n",
    "p = Thread(target=fit_static_model)\n",
    "p.start()\n",
    "p.join()\n",
    "static_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "14da249aea668dd476485a6222a8c1fd2f2cd90c7005afa5442c69b6c853f2dc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
